{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Mental Health Signal Detection in Arabic Tweets\n",
    "## A Comprehensive Research Framework\n",
    "\n",
    "### Research Objectives:\n",
    "1. **Primary Goal**: Develop a robust multi-class classification system for detecting mental health signals in Arabic social media text\n",
    "2. **Secondary Goals**:\n",
    "   - Address class imbalance through advanced techniques\n",
    "   - Leverage Arabic-specific NLP models and preprocessing\n",
    "   - Implement interpretable ML approaches for clinical validity\n",
    "   - Ensure ethical considerations in mental health AI applications\n",
    "\n",
    "### Key Improvements:\n",
    "- Arabic-specific text preprocessing and normalization\n",
    "- Advanced feature engineering including psycholinguistic features\n",
    "- State-of-the-art transformer models (AraBERT, CAMeLBERT)\n",
    "- Proper handling of severe class imbalance\n",
    "- Rigorous evaluation with clinical relevance metrics\n",
    "- Model interpretability and error analysis\n",
    "- Ethical considerations and bias detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cant be put in requirements.txt so it goes here. Restart the kernel after running this.\n",
    "pip install emoji==1.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0\n",
      "Transformers version: 4.43.4\n",
      "CUDA available: False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Data handling\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "# Fix emoji library compatibility issue\n",
    "try:\n",
    "    import emoji\n",
    "    # For emoji 2.0+, use the new API\n",
    "    if hasattr(emoji, 'EMOJI_DATA'):\n",
    "        EMOJI_DATA = emoji.EMOJI_DATA\n",
    "    else:\n",
    "        # For newer versions, emoji functionality is handled differently\n",
    "        EMOJI_DATA = None\n",
    "except ImportError:\n",
    "    EMOJI_DATA = None\n",
    "\n",
    "# Arabic NLP libraries\n",
    "import pyarabic.araby as araby\n",
    "import camel_tools\n",
    "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
    "from camel_tools.utils.normalize import normalize_alef_ar\n",
    "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from arabert import ArabertPreprocessor\n",
    "from farasa.segmenter import FarasaSegmenter\n",
    "from farasa.pos import FarasaPOSTagger\n",
    "from farasa.stemmer import FarasaStemmer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, GridSearchCV, \n",
    "    RandomizedSearchCV, cross_val_score, cross_validate\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    precision_recall_curve, roc_curve, auc, matthews_corrcoef,\n",
    "    cohen_kappa_score, make_scorer\n",
    ")\n",
    "\n",
    "# Advanced ML algorithms\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Class imbalance handling\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments, EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding, get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "# Model interpretation\n",
    "import shap\n",
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# Visualization\n",
    "from wordcloud import WordCloud\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install emoji==1.7.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET OVERVIEW\n",
      "================================================================================\n",
      "Total samples: 48,856\n",
      "Total features: 39\n",
      "\n",
      "Class Distribution:\n",
      "  neutral             : 42,931 (90.14%)\n",
      "  depression          :  3,206 ( 6.73%)\n",
      "  anxiety             :    939 ( 1.97%)\n",
      "  suicidal_ideation   :    549 ( 1.15%)\n",
      "\n",
      "Class Imbalance Ratio: 78.20:1\n",
      "Minority class: suicidal_ideation (549 samples)\n",
      "Majority class: neutral (42931 samples)\n",
      "\n",
      "================================================================================\n",
      "DATA QUALITY CHECKS\n",
      "================================================================================\n",
      "Missing values in 'text': 0\n",
      "Duplicate texts: 0\n",
      "Empty texts: 0\n",
      "\n",
      "Text Length Statistics:\n",
      "count    48856.00000\n",
      "mean        92.09835\n",
      "std         72.44827\n",
      "min         15.00000\n",
      "25%         36.00000\n",
      "50%         65.00000\n",
      "75%        128.00000\n",
      "max        280.00000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('datasets/arabic_tweets_matched_classifications.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"Total features: {len(df.columns)}\")\n",
    "print(f\"\\nClass Distribution:\")\n",
    "class_dist = df['classification'].value_counts()\n",
    "class_pct = df['classification'].value_counts(normalize=True) * 100\n",
    "\n",
    "for cls in class_dist.index:\n",
    "    print(f\"  {cls:20s}: {class_dist[cls]:6,} ({class_pct[cls]:5.2f}%)\")\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "imbalance_ratio = class_dist.max() / class_dist.min()\n",
    "print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Minority class: {class_dist.idxmin()} ({class_dist.min()} samples)\")\n",
    "print(f\"Majority class: {class_dist.idxmax()} ({class_dist.max()} samples)\")\n",
    "\n",
    "# Data quality checks\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Missing values in 'text': {df['text'].isna().sum()}\")\n",
    "print(f\"Duplicate texts: {df['text'].duplicated().sum()}\")\n",
    "print(f\"Empty texts: {(df['text'].str.strip() == '').sum()}\")\n",
    "\n",
    "# Text statistics\n",
    "df['text_length'] = df['text'].str.len()\n",
    "print(f\"\\nText Length Statistics:\")\n",
    "print(df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#FF6B6B",
           "#4ECDC4",
           "#45B7D1",
           "#FFA07A"
          ]
         },
         "showlegend": false,
         "text": {
          "bdata": "AAAAAGD25EAAAAAAAAypQAAAAAAAWI1AAAAAAAAogUA=",
          "dtype": "f8"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "neutral",
          "depression",
          "anxiety",
          "suicidal_ideation"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "s6cAAIYMAACrAwAAJQIAAA==",
          "dtype": "i4"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           "#FF6B6B",
           "#4ECDC4",
           "#45B7D1",
           "#FFA07A"
          ]
         },
         "showlegend": false,
         "text": {
          "bdata": "AAAAAGD25EAAAAAAAAypQAAAAAAAWI1AAAAAAAAogUA=",
          "dtype": "f8"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "neutral",
          "depression",
          "anxiety",
          "suicidal_ideation"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "s6cAAIYMAACrAwAAJQIAAA==",
          "dtype": "i4"
         },
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Class Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Class Distribution (Log Scale)",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 400,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Mental Health Classification Distribution"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Class"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Class"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count (Log Scale)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize class distribution\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Class Distribution', 'Class Distribution (Log Scale)'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Regular scale\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=class_dist.index,\n",
    "        y=class_dist.values,\n",
    "        text=class_dist.values,\n",
    "        textposition='outside',\n",
    "        marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'],\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Log scale\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=class_dist.index,\n",
    "        y=class_dist.values,\n",
    "        text=class_dist.values,\n",
    "        textposition='outside',\n",
    "        marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'],\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Count (Log Scale)\", type=\"log\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Class\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Class\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Mental Health Classification Distribution\",\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Arabic Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Optional: Using Complement NB with TF-IDF Only Features\n",
    "\n",
    "If you want to use Complement Naive Bayes, it requires **non-negative features**. You can use it with TF-IDF features only (which are always non-negative):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Train Complement NB with TF-IDF only features (non-negative)\n",
    "# Uncomment to run:\n",
    "\n",
    "# complement_nb_model = ComplementNB(alpha=1.0)\n",
    "# complement_nb_model.fit(X_train_tfidf_only, y_train)\n",
    "# y_pred_cnb = complement_nb_model.predict(X_test_tfidf_only)\n",
    "# \n",
    "# print(\"Complement NB Performance (TF-IDF only):\")\n",
    "# print(f\"F1 Weighted: {f1_score(y_test, y_pred_cnb, average='weighted'):.4f}\")\n",
    "# print(f\"F1 Macro: {f1_score(y_test, y_pred_cnb, average='macro'):.4f}\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred_cnb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic text preprocessor initialized\n"
     ]
    }
   ],
   "source": [
    "class ArabicTextPreprocessor:\n",
    "    \"\"\"Advanced Arabic text preprocessing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 remove_diacritics=True,\n",
    "                 normalize_arabic=True,\n",
    "                 remove_punctuation=True,\n",
    "                 remove_english=False,\n",
    "                 remove_numbers=False,\n",
    "                 remove_extra_spaces=True,\n",
    "                 apply_stemming=False,\n",
    "                 apply_segmentation=False):\n",
    "        \n",
    "        self.remove_diacritics = remove_diacritics\n",
    "        self.normalize_arabic = normalize_arabic\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.remove_english = remove_english\n",
    "        self.remove_numbers = remove_numbers\n",
    "        self.remove_extra_spaces = remove_extra_spaces\n",
    "        self.apply_stemming = apply_stemming\n",
    "        self.apply_segmentation = apply_segmentation\n",
    "        \n",
    "        # Initialize Arabic NLP tools\n",
    "        if self.apply_stemming:\n",
    "            self.stemmer = FarasaStemmer()\n",
    "        if self.apply_segmentation:\n",
    "            self.segmenter = FarasaSegmenter()\n",
    "        \n",
    "        # Arabic-specific patterns\n",
    "        self.arabic_punct = 'ÿåÿõÿü'\n",
    "        self.emoticons_pattern = re.compile(r'[:;=][-~]?[)D(|\\/@]|[)D(|\\/@][-~]?[:;=]')\n",
    "        \n",
    "        # Mental health keywords (for feature extraction)\n",
    "        self.depression_keywords = [\n",
    "            'ÿ≠ÿ≤ŸÜ', 'ÿßŸÉÿ™ÿ¶ÿßÿ®', 'Ÿäÿ£ÿ≥', 'Ÿàÿ≠ÿØÿ©', 'ÿ£ŸÑŸÖ', 'ÿ®ŸÉÿßÿ°', 'ÿØŸÖŸàÿπ',\n",
    "            'ŸÅÿ±ÿßÿ∫', 'ÿ∂Ÿäÿßÿπ', 'ÿ™ÿπÿ®', 'ÿ•ÿ±ŸáÿßŸÇ', 'ÿßŸÜŸáŸäÿßÿ±', 'ŸÉÿ≥ÿ±', 'ŸÖŸàÿ™'\n",
    "        ]\n",
    "        self.anxiety_keywords = [\n",
    "            'ŸÇŸÑŸÇ', 'ÿÆŸàŸÅ', 'ÿ™Ÿàÿ™ÿ±', 'ÿ∂ÿ∫ÿ∑', 'ŸáŸÑÿπ', 'ÿ±ÿπÿ®', 'ÿßÿ∂ÿ∑ÿ±ÿßÿ®',\n",
    "            'ÿπÿµÿ®Ÿäÿ©', 'ÿßÿ±ÿ™ÿ®ÿßŸÉ', 'ÿ∞ÿπÿ±', 'ŸÅÿ≤ÿπ', 'ÿ±Ÿáÿßÿ®'\n",
    "        ]\n",
    "        self.suicide_keywords = [\n",
    "            'ÿßŸÜÿ™ÿ≠ÿßÿ±', 'ŸÖŸàÿ™', 'ŸÇÿ™ŸÑ ŸÜŸÅÿ≥', 'ŸÜŸáÿßŸäÿ©', 'ŸàÿØÿßÿπ', 'ÿ£ÿ∞Ÿâ',\n",
    "            'ÿ¨ÿ±ÿ≠', 'ÿ£ŸÑŸÖ ÿ¥ÿØŸäÿØ', 'ŸÑÿß ÿ£ÿ±ŸäÿØ ÿßŸÑÿπŸäÿ¥', 'ÿ≥ÿ¶ŸÖÿ™ ÿßŸÑÿ≠Ÿäÿßÿ©'\n",
    "        ]\n",
    "        \n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"Normalize Arabic text\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "            \n",
    "        # Normalize Arabic characters\n",
    "        if self.normalize_arabic:\n",
    "            text = normalize_alef_ar(text)\n",
    "            text = normalize_alef_maksura_ar(text)\n",
    "            text = normalize_teh_marbuta_ar(text)\n",
    "            \n",
    "            # Additional normalizations\n",
    "            text = re.sub(r'[ÿ•ÿ£ÿ¢ÿß]', 'ÿß', text)\n",
    "            text = re.sub(r'Ÿâ', 'Ÿä', text)\n",
    "            text = re.sub(r'ÿ©', 'Ÿá', text)\n",
    "            text = re.sub(r'⁄Ø', 'ŸÉ', text)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean text with various options\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "            \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "        \n",
    "        # Remove mentions and hashtags (but keep the text)\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "        \n",
    "        # Remove diacritics\n",
    "        if self.remove_diacritics:\n",
    "            text = araby.strip_diacritics(text)\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punctuation:\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation + self.arabic_punct))\n",
    "            \n",
    "        # Remove English characters\n",
    "        if self.remove_english:\n",
    "            text = re.sub(r'[a-zA-Z]', '', text)\n",
    "            \n",
    "        # Remove numbers\n",
    "        if self.remove_numbers:\n",
    "            text = re.sub(r'\\d+', '', text)\n",
    "            \n",
    "        # Remove extra spaces\n",
    "        if self.remove_extra_spaces:\n",
    "            text = ' '.join(text.split())\n",
    "            \n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_features(self, text):\n",
    "        \"\"\"Extract psycholinguistic features\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Emotional indicators\n",
    "        features['depression_score'] = sum(1 for word in self.depression_keywords if word in text)\n",
    "        features['anxiety_score'] = sum(1 for word in self.anxiety_keywords if word in text)\n",
    "        features['suicide_score'] = sum(1 for word in self.suicide_keywords if word in text)\n",
    "        \n",
    "        # Text characteristics\n",
    "        features['exclamation_count'] = text.count('!')\n",
    "        features['question_count'] = text.count('ÿü') + text.count('?')\n",
    "        features['ellipsis_count'] = len(re.findall(r'\\.{2,}', text))\n",
    "        features['caps_ratio'] = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
    "        \n",
    "        # Emoticon detection\n",
    "        features['emoticon_count'] = len(self.emoticons_pattern.findall(text))\n",
    "        \n",
    "        # Repetition patterns\n",
    "        features['char_repetition'] = len(re.findall(r'(.)\\1{2,}', text))\n",
    "        features['word_repetition'] = self._count_repeated_words(text)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _count_repeated_words(self, text):\n",
    "        \"\"\"Count repeated words in text\"\"\"\n",
    "        words = text.split()\n",
    "        if len(words) < 2:\n",
    "            return 0\n",
    "        return sum(1 for i in range(1, len(words)) if words[i] == words[i-1])\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Main preprocessing pipeline\"\"\"\n",
    "        # Clean and normalize\n",
    "        text = self.clean_text(text)\n",
    "        text = self.normalize_text(text)\n",
    "        \n",
    "        # Apply stemming if requested\n",
    "        if self.apply_stemming and hasattr(self, 'stemmer'):\n",
    "            text = self.stemmer.stem(text)\n",
    "            \n",
    "        # Apply segmentation if requested  \n",
    "        if self.apply_segmentation and hasattr(self, 'segmenter'):\n",
    "            text = self.segmenter.segment(text)\n",
    "            \n",
    "        return text\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = ArabicTextPreprocessor(\n",
    "    remove_diacritics=True,\n",
    "    normalize_arabic=True,\n",
    "    remove_punctuation=False,  # Keep for feature extraction\n",
    "    remove_english=False,\n",
    "    remove_numbers=False\n",
    ")\n",
    "\n",
    "print(\"Arabic text preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping NaN rows: (47625, 40)\n"
     ]
    }
   ],
   "source": [
    "# üîπ Drop all rows that contain ANY NaN values\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Shape after dropping NaN rows:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8ad926c7e94aaa90d6b9b8bc4fbfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting psycholinguistic features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefa1a37a8464d20a771a71839d03634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing complete!\n",
      "Added 10 psycholinguistic features\n",
      "\n",
      "Sample preprocessed texts:\n",
      "\n",
      "Original: ÿ®ÿßÿ±ŸäŸÑŸÑÿß ÿµÿßÿ±ŸÑŸá ŸÉŸÖ ŸÖÿ®ÿßÿ±ÿßŸá ŸÖÿ≥ÿ™ŸàÿßŸá ÿ≥Ÿäÿ° ŸÅŸäÿØÿßŸÑ ÿ®ÿ≥ Ÿäÿ∂ÿ±ÿ® ÿ®ÿ±Ÿàÿ≤Ÿà ŸÖÿ≤ÿßÿ¨Ÿá ÿ≤Ÿä ÿßŸÑÿ≤ŸÅÿ™ ÿßÿÆÿ± ŸÉŸÖ ŸÖÿ®ÿßÿ±ÿßŸá Ÿàÿ≥ÿ∑ ÿπŸÇŸäŸÖ ÿ¨ÿØÿß...\n",
      "Processed: ÿ®ÿßÿ±ŸäŸÑŸÑÿß ÿµÿßÿ±ŸÑŸá ŸÉŸÖ ŸÖÿ®ÿßÿ±ÿßŸá ŸÖÿ≥ÿ™ŸàÿßŸá ÿ≥Ÿäÿ° ŸÅŸäÿØÿßŸÑ ÿ®ÿ≥ Ÿäÿ∂ÿ±ÿ® ÿ®ÿ±Ÿàÿ≤Ÿà ŸÖÿ≤ÿßÿ¨Ÿá ÿ≤Ÿä ÿßŸÑÿ≤ŸÅÿ™ ÿßÿÆÿ± ŸÉŸÖ ŸÖÿ®ÿßÿ±ÿßŸá Ÿàÿ≥ÿ∑ ÿπŸÇŸäŸÖ ÿ¨ÿØÿß...\n",
      "Class: neutral\n",
      "\n",
      "Original: ÿ≠ÿ≥ÿßÿ® ÿπÿ∏ŸäŸÖ ÿßÿÆÿ± ŸáŸÖŸá ÿßÿ´ÿßÿ±Ÿá ÿßŸÑÿ¨ÿØŸÑ ÿ™ŸÅŸÉŸäÿ± ÿπŸÖŸäŸÇ Ÿàÿ™ÿ≠ŸÑŸäŸÑ ŸÇŸàŸä ÿ¨ÿØÿß ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿπÿßŸÖ ŸàÿßŸÑŸÑŸá...\n",
      "Processed: ÿ≠ÿ≥ÿßÿ® ÿπÿ∏ŸäŸÖ ÿßÿÆÿ± ŸáŸÖŸá ÿßÿ´ÿßÿ±Ÿá ÿßŸÑÿ¨ÿØŸÑ ÿ™ŸÅŸÉŸäÿ± ÿπŸÖŸäŸÇ Ÿàÿ™ÿ≠ŸÑŸäŸÑ ŸÇŸàŸä ÿ¨ÿØÿß ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿπÿßŸÖ ŸàÿßŸÑŸÑŸá...\n",
      "Class: neutral\n",
      "\n",
      "Original: ÿØÿÆŸÑ ŸÑÿßÿ¨ÿßŸÖŸä ŸÖŸÉÿßŸÜ ŸÖÿßÿØŸà ÿßŸÑŸä ŸÇÿßÿ™ŸÑ ÿßŸÑŸÑÿπÿ® Ÿàÿ±ÿßÿ° ŸàÿØÿÆŸÑ ÿßŸÑŸÜÿ¨ÿπŸä ŸÖŸÉÿßŸÜ ÿßŸÑÿÆŸäÿ®ÿ±Ÿä ÿßŸÑŸä ŸÉŸÑ ŸÉŸàÿ±Ÿá ÿ∫ŸÑÿ∑ Ÿàÿ±ÿßÿ¶ÿØ ÿßÿÆÿ± ÿ±ÿ®ÿπ ÿ≥ÿßÿπŸá...\n",
      "Processed: ÿØÿÆŸÑ ŸÑÿßÿ¨ÿßŸÖŸä ŸÖŸÉÿßŸÜ ŸÖÿßÿØŸà ÿßŸÑŸä ŸÇÿßÿ™ŸÑ ÿßŸÑŸÑÿπÿ® Ÿàÿ±ÿßÿ° ŸàÿØÿÆŸÑ ÿßŸÑŸÜÿ¨ÿπŸä ŸÖŸÉÿßŸÜ ÿßŸÑÿÆŸäÿ®ÿ±Ÿä ÿßŸÑŸä ŸÉŸÑ ŸÉŸàÿ±Ÿá ÿ∫ŸÑÿ∑ Ÿàÿ±ÿßÿ¶ÿØ ÿßÿÆÿ± ÿ±ÿ®ÿπ ÿ≥ÿßÿπŸá...\n",
      "Class: neutral\n"
     ]
    }
   ],
   "source": [
    "# Preprocess texts and extract features\n",
    "print(\"Preprocessing texts...\")\n",
    "df['processed_text'] = df['text'].progress_apply(preprocessor.preprocess)\n",
    "\n",
    "print(\"Extracting psycholinguistic features...\")\n",
    "psych_features = df['text'].progress_apply(preprocessor.extract_features)\n",
    "psych_features_df = pd.DataFrame(list(psych_features))\n",
    "\n",
    "# Combine with existing features\n",
    "df = pd.concat([df, psych_features_df], axis=1)\n",
    "\n",
    "print(f\"\\nPreprocessing complete!\")\n",
    "print(f\"Added {len(psych_features_df.columns)} psycholinguistic features\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample preprocessed texts:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nOriginal: {df['text'].iloc[i][:100]}...\")\n",
    "    print(f\"Processed: {df['processed_text'].iloc[i][:100]}...\")\n",
    "    print(f\"Class: {df['classification'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install IProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineer initialized\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineer:\n",
    "    \"\"\"Comprehensive feature engineering for Arabic mental health text\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tfidf_vectorizer = None\n",
    "        self.count_vectorizer = None\n",
    "        self.char_vectorizer = None\n",
    "        \n",
    "    def create_tfidf_features(self, texts, max_features=5000, ngram_range=(1, 3)):\n",
    "        \"\"\"Create TF-IDF features\"\"\"\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            ngram_range=ngram_range,\n",
    "            analyzer='word',\n",
    "            min_df=5,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True,\n",
    "            use_idf=True\n",
    "        )\n",
    "        return self.tfidf_vectorizer.fit_transform(texts)\n",
    "    \n",
    "    def create_char_ngram_features(self, texts, max_features=3000):\n",
    "        \"\"\"Create character n-gram features\"\"\"\n",
    "        self.char_vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            ngram_range=(2, 5),\n",
    "            analyzer='char',\n",
    "            min_df=5,\n",
    "            max_df=0.95\n",
    "        )\n",
    "        return self.char_vectorizer.fit_transform(texts)\n",
    "    \n",
    "    def create_topic_features(self, tfidf_matrix, n_topics=20):\n",
    "        \"\"\"Create topic modeling features using NMF\"\"\"\n",
    "        nmf = NMF(n_components=n_topics, random_state=42)\n",
    "        topic_features = nmf.fit_transform(tfidf_matrix)\n",
    "        return topic_features, nmf\n",
    "    \n",
    "    def create_embedding_features(self, texts, model_name='aubmindlab/bert-base-arabertv2'):\n",
    "        \"\"\"Create contextual embeddings using AraBERT\"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        embeddings = []\n",
    "        batch_size = 32\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(0, len(texts), batch_size)):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                \n",
    "                inputs = tokenizer(\n",
    "                    batch_texts,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128,\n",
    "                    return_tensors='pt'\n",
    "                ).to(device)\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                # Use [CLS] token embedding\n",
    "                batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                embeddings.extend(batch_embeddings)\n",
    "                \n",
    "        return np.array(embeddings)\n",
    "    \n",
    "    def combine_features(self, *feature_arrays):\n",
    "        \"\"\"Combine multiple feature arrays\"\"\"\n",
    "        # Convert sparse matrices to dense if needed\n",
    "        dense_features = []\n",
    "        for feat in feature_arrays:\n",
    "            if hasattr(feat, 'toarray'):\n",
    "                dense_features.append(feat.toarray())\n",
    "            else:\n",
    "                dense_features.append(feat)\n",
    "        \n",
    "        return np.hstack(dense_features)\n",
    "\n",
    "# Initialize feature engineer\n",
    "feature_engineer = FeatureEngineer()\n",
    "print(\"Feature engineer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature sets...\n",
      "\n",
      "1. Creating TF-IDF features...\n",
      "   TF-IDF shape: (47625, 5000)\n",
      "\n",
      "2. Creating character n-gram features...\n",
      "   Character n-gram shape: (47625, 3000)\n",
      "\n",
      "3. Creating topic features...\n",
      "   Topic features shape: (47625, 20)\n",
      "\n",
      "4. Preparing numerical features...\n",
      "   Numerical features shape: (47625, 33)\n",
      "\n",
      "============================================================\n",
      "Total feature dimensions created: \n",
      "  - TF-IDF: 5000\n",
      "  - Character n-grams: 3000\n",
      "  - Topics: 20\n",
      "  - Numerical: 33\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create various feature sets\n",
    "print(\"Creating feature sets...\\n\")\n",
    "\n",
    "# 1. TF-IDF features\n",
    "print(\"1. Creating TF-IDF features...\")\n",
    "tfidf_features = feature_engineer.create_tfidf_features(\n",
    "    df['processed_text'].values,\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 3)\n",
    ")\n",
    "print(f\"   TF-IDF shape: {tfidf_features.shape}\")\n",
    "\n",
    "# 2. Character n-gram features\n",
    "print(\"\\n2. Creating character n-gram features...\")\n",
    "char_features = feature_engineer.create_char_ngram_features(\n",
    "    df['processed_text'].values,\n",
    "    max_features=3000\n",
    ")\n",
    "print(f\"   Character n-gram shape: {char_features.shape}\")\n",
    "\n",
    "# 3. Topic features\n",
    "print(\"\\n3. Creating topic features...\")\n",
    "topic_features, nmf_model = feature_engineer.create_topic_features(\n",
    "    tfidf_features,\n",
    "    n_topics=20\n",
    ")\n",
    "print(f\"   Topic features shape: {topic_features.shape}\")\n",
    "\n",
    "# 4. Numerical features\n",
    "print(\"\\n4. Preparing numerical features...\")\n",
    "numerical_features = [\n",
    "    'char_count', 'word_count', 'sentence_count', 'avg_words_per_sentence',\n",
    "    'mention_count', 'hashtag_count', 'url_count',\n",
    "    'punctuation_count', 'exclamation_count', 'question_count', 'emoji_count',\n",
    "    'arabic_char_count', 'arabic_ratio', 'repeated_chars',\n",
    "    'latin_char_count', 'latin_ratio', 'digit_count', 'digit_ratio',\n",
    "    'unique_words', 'lexical_diversity', 'avg_word_length',\n",
    "    'ellipsis_count', 'space_count',\n",
    "    # Psycholinguistic features\n",
    "    'depression_score', 'anxiety_score', 'suicide_score',\n",
    "    'caps_ratio', 'emoticon_count', 'char_repetition', 'word_repetition'\n",
    "]\n",
    "\n",
    "# Check which features exist\n",
    "available_numerical = [f for f in numerical_features if f in df.columns]\n",
    "numerical_feat_array = df[available_numerical].values\n",
    "print(f\"   Numerical features shape: {numerical_feat_array.shape}\")\n",
    "\n",
    "# 5. Scale numerical features\n",
    "scaler = RobustScaler()\n",
    "numerical_feat_scaled = scaler.fit_transform(numerical_feat_array)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Total feature dimensions created: \")\n",
    "print(f\"  - TF-IDF: {tfidf_features.shape[1]}\")\n",
    "print(f\"  - Character n-grams: {char_features.shape[1]}\")\n",
    "print(f\"  - Topics: {topic_features.shape[1]}\")\n",
    "print(f\"  - Numerical: {numerical_feat_scaled.shape[1]}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Splitting and Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding:\n",
      "  0: anxiety\n",
      "  1: depression\n",
      "  2: neutral\n",
      "  3: suicidal_ideation\n",
      "\n",
      "Combining feature sets...\n",
      "Combined features shape: (47625, 5053)\n",
      "TF-IDF + Numerical shape: (47625, 5033)\n",
      "Char + Numerical shape: (47625, 3033)\n",
      "\n",
      "Training set: (38100, 5053)\n",
      "Test set: (9525, 5053)\n",
      "\n",
      "Training label distribution:\n",
      "  anxiety: 751 (1.97%)\n",
      "  depression: 2565 (6.73%)\n",
      "  neutral: 34345 (90.14%)\n",
      "  suicidal_ideation: 439 (1.15%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['classification'])\n",
    "\n",
    "# Create mapping\n",
    "label_mapping = dict(zip(label_encoder.transform(label_encoder.classes_), \n",
    "                        label_encoder.classes_))\n",
    "print(\"Label Encoding:\")\n",
    "for idx, label in label_mapping.items():\n",
    "    print(f\"  {idx}: {label}\")\n",
    "\n",
    "# Combine feature sets\n",
    "print(\"\\nCombining feature sets...\")\n",
    "\n",
    "# Option 1: All features combined\n",
    "X_combined = feature_engineer.combine_features(\n",
    "    tfidf_features,\n",
    "    numerical_feat_scaled,\n",
    "    topic_features\n",
    ")\n",
    "\n",
    "# Option 2: TF-IDF + Numerical\n",
    "X_tfidf_num = feature_engineer.combine_features(\n",
    "    tfidf_features,\n",
    "    numerical_feat_scaled\n",
    ")\n",
    "\n",
    "# Option 3: Character n-grams + Numerical\n",
    "X_char_num = feature_engineer.combine_features(\n",
    "    char_features,\n",
    "    numerical_feat_scaled\n",
    ")\n",
    "\n",
    "print(f\"Combined features shape: {X_combined.shape}\")\n",
    "print(f\"TF-IDF + Numerical shape: {X_tfidf_num.shape}\")\n",
    "print(f\"Char + Numerical shape: {X_char_num.shape}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Also split text for deep learning models\n",
    "X_train_text, X_test_text = train_test_split(\n",
    "    df['processed_text'].values, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTraining label distribution:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  {label_mapping[u]}: {c} ({c/len(y_train)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing class imbalance strategies...\n",
      "\n",
      "Class weights:\n",
      "  anxiety: 12.683\n",
      "  depression: 3.713\n",
      "  neutral: 0.277\n",
      "  suicidal_ideation: 21.697\n",
      "\n",
      "Creating resampled datasets...\n",
      "SMOTE: (137380, 5053)\n",
      "Borderline-SMOTE: (137380, 5053)\n",
      "ADASYN: (137277, 5053)\n",
      "SMOTE+Tomek: (137378, 5053)\n",
      "\n",
      "Resampled label distributions:\n",
      "\n",
      "SMOTE:\n",
      "  anxiety: 34345\n",
      "  depression: 34345\n",
      "  neutral: 34345\n",
      "  suicidal_ideation: 34345\n",
      "\n",
      "Borderline-SMOTE:\n",
      "  anxiety: 34345\n",
      "  depression: 34345\n",
      "  neutral: 34345\n",
      "  suicidal_ideation: 34345\n",
      "\n",
      "ADASYN:\n",
      "  anxiety: 34449\n",
      "  depression: 34086\n",
      "  neutral: 34345\n",
      "  suicidal_ideation: 34397\n",
      "\n",
      "SMOTE+Tomek:\n",
      "  anxiety: 34345\n",
      "  depression: 34344\n",
      "  neutral: 34344\n",
      "  suicidal_ideation: 34345\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance with multiple strategies\n",
    "print(\"Implementing class imbalance strategies...\\n\")\n",
    "\n",
    "# 1. Class weights for weighted loss\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "print(\"Class weights:\")\n",
    "for cls, weight in class_weight_dict.items():\n",
    "    print(f\"  {label_mapping[cls]}: {weight:.3f}\")\n",
    "\n",
    "# 2. SMOTE variants\n",
    "print(\"\\nCreating resampled datasets...\")\n",
    "\n",
    "# Standard SMOTE\n",
    "smote = SMOTE(random_state=RANDOM_SEED, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTE: {X_train_smote.shape}\")\n",
    "\n",
    "# Borderline SMOTE (better for borderline cases)\n",
    "borderline_smote = BorderlineSMOTE(random_state=RANDOM_SEED, k_neighbors=5)\n",
    "X_train_bsmote, y_train_bsmote = borderline_smote.fit_resample(X_train, y_train)\n",
    "print(f\"Borderline-SMOTE: {X_train_bsmote.shape}\")\n",
    "\n",
    "# ADASYN (adaptive synthetic sampling)\n",
    "adasyn = ADASYN(random_state=RANDOM_SEED, n_neighbors=5)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "print(f\"ADASYN: {X_train_adasyn.shape}\")\n",
    "\n",
    "# Combined approach: SMOTE + Tomek\n",
    "smote_tomek = SMOTETomek(random_state=RANDOM_SEED)\n",
    "X_train_combined, y_train_combined = smote_tomek.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTE+Tomek: {X_train_combined.shape}\")\n",
    "\n",
    "print(\"\\nResampled label distributions:\")\n",
    "for name, y_resampled in [('SMOTE', y_train_smote), \n",
    "                          ('Borderline-SMOTE', y_train_bsmote),\n",
    "                          ('ADASYN', y_train_adasyn),\n",
    "                          ('SMOTE+Tomek', y_train_combined)]:\n",
    "    unique, counts = np.unique(y_resampled, return_counts=True)\n",
    "    print(f\"\\n{name}:\")\n",
    "    for u, c in zip(unique, counts):\n",
    "        print(f\"  {label_mapping[u]}: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training - Traditional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 9 models for evaluation\n"
     ]
    }
   ],
   "source": [
    "# Define comprehensive model suite\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000, \n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'Ridge Classifier': RidgeClassifier(\n",
    "        alpha=1.0,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'Linear SVM': LinearSVC(\n",
    "        max_iter=10000,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Extra Trees': ExtraTreesClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=1,\n",
    "        random_state=RANDOM_SEED,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbosity=-1\n",
    "    ),\n",
    "    'CatBoost': CatBoostClassifier(\n",
    "        iterations=200,\n",
    "        depth=6,\n",
    "        learning_rate=0.1,\n",
    "        class_weights=class_weight_dict,\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbose=False\n",
    "    ),\n",
    "    'MLP': MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128, 64),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        max_iter=500,\n",
    "        random_state=RANDOM_SEED,\n",
    "        early_stopping=True\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(models)} models for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING ON ORIGINAL DATA\n",
      "================================================================================\n",
      "Found checkpoint at models/training_progress/ml_models_checkpoint.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6beb89b066e4b3fa6730ad62c2e3eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "üíæ Checkpoint saved (1/10 models completed)\n",
      "  CV F1 (weighted): 0.8007 (+/- 0.0047)\n",
      "  Test F1 (weighted): 0.7965\n",
      "  Test F1 (macro): 0.4054\n",
      "\n",
      "Training Ridge Classifier...\n",
      "üíæ Checkpoint saved (2/11 models completed)\n",
      "  CV F1 (weighted): 0.7789 (+/- 0.0060)\n",
      "  Test F1 (weighted): 0.7696\n",
      "  Test F1 (macro): 0.3722\n",
      "\n",
      "Training Linear SVM...\n",
      "üíæ Checkpoint saved (3/12 models completed)\n",
      "  CV F1 (weighted): 0.8729 (+/- 0.0023)\n",
      "  Test F1 (weighted): 0.8723\n",
      "  Test F1 (macro): 0.4683\n",
      "\n",
      "Training Random Forest...\n",
      "üíæ Checkpoint saved (4/13 models completed)\n",
      "  CV F1 (weighted): 0.8086 (+/- 0.0061)\n",
      "  Test F1 (weighted): 0.7930\n",
      "  Test F1 (macro): 0.3705\n",
      "\n",
      "Training Extra Trees...\n",
      "üíæ Checkpoint saved (5/14 models completed)\n",
      "  CV F1 (weighted): 0.7140 (+/- 0.0186)\n",
      "  Test F1 (weighted): 0.6975\n",
      "  Test F1 (macro): 0.3230\n",
      "\n",
      "Training XGBoost...\n",
      "‚ùå Error training XGBoost: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "   Skipping this model and continuing...\n",
      "\n",
      "Training LightGBM...\n",
      "‚ùå Error training LightGBM: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "   Skipping this model and continuing...\n",
      "\n",
      "Training CatBoost...\n",
      "üíæ Checkpoint saved (6/15 models completed)\n",
      "  CV F1 (weighted): 0.6746 (+/- 0.0050)\n",
      "  Test F1 (weighted): 0.6726\n",
      "  Test F1 (macro): 0.3139\n",
      "\n",
      "Training MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Checkpoint saved (7/16 models completed)\n",
      "  CV F1 (weighted): 0.8785 (+/- 0.0042)\n",
      "  Test F1 (weighted): 0.8833\n",
      "  Test F1 (macro): 0.3841\n",
      "\n",
      "================================================================================\n",
      "TRAINING ON SMOTE RESAMPLED DATA\n",
      "================================================================================\n",
      "Found checkpoint at models/training_progress/ml_models_checkpoint.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9b737c68744e87bc1d0200f29a129f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "üíæ Checkpoint saved (1/10 models completed)\n",
      "  CV F1 (weighted): 0.9123 (+/- 0.0024)\n",
      "  Test F1 (weighted): 0.8147\n",
      "  Test F1 (macro): 0.4130\n",
      "\n",
      "Training Ridge Classifier...\n",
      "üíæ Checkpoint saved (2/11 models completed)\n",
      "  CV F1 (weighted): 0.8988 (+/- 0.0025)\n",
      "  Test F1 (weighted): 0.7789\n",
      "  Test F1 (macro): 0.3725\n",
      "\n",
      "Training Linear SVM...\n",
      "üíæ Checkpoint saved (3/12 models completed)\n",
      "  CV F1 (weighted): 0.9280 (+/- 0.0022)\n",
      "  Test F1 (weighted): 0.8140\n",
      "  Test F1 (macro): 0.4036\n",
      "\n",
      "Training Random Forest...\n",
      "üíæ Checkpoint saved (4/13 models completed)\n",
      "  CV F1 (weighted): 0.8925 (+/- 0.0019)\n",
      "  Test F1 (weighted): 0.8086\n",
      "  Test F1 (macro): 0.3604\n",
      "\n",
      "Training Extra Trees...\n",
      "üíæ Checkpoint saved (5/14 models completed)\n",
      "  CV F1 (weighted): 0.8354 (+/- 0.0016)\n",
      "  Test F1 (weighted): 0.7645\n",
      "  Test F1 (macro): 0.3532\n",
      "\n",
      "Training XGBoost...\n",
      "‚ùå Error training XGBoost: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "   Skipping this model and continuing...\n",
      "\n",
      "Training LightGBM...\n",
      "‚ùå Error training LightGBM: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "   Skipping this model and continuing...\n",
      "\n",
      "Training CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/rouaanaim/My Projects/aicc-project/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Checkpoint saved (6/15 models completed)\n",
      "  CV F1 (weighted): 0.4977 (+/- 0.0018)\n",
      "  Test F1 (weighted): 0.0144\n",
      "  Test F1 (macro): 0.0813\n",
      "\n",
      "Training MLP...\n",
      "üíæ Checkpoint saved (7/16 models completed)\n",
      "  CV F1 (weighted): 0.9843 (+/- 0.0010)\n",
      "  Test F1 (weighted): 0.8739\n",
      "  Test F1 (macro): 0.4214\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation function with checkpoint saving\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test, cv_folds=5, checkpoint_dir='models/training_progress'):\n",
    "    \"\"\"Comprehensive model evaluation with cross-validation and checkpoint saving\"\"\"\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_file = os.path.join(checkpoint_dir, 'ml_models_checkpoint.pkl')\n",
    "    \n",
    "    # Try to load existing checkpoint\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(f\"Found checkpoint at {checkpoint_file}\")\n",
    "        response = input(\"Resume from checkpoint? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            results = joblib.load(checkpoint_file)\n",
    "            completed_models = list(results.keys())\n",
    "            print(f\"‚úÖ Loaded checkpoint with {len(completed_models)} completed models: {completed_models}\")\n",
    "            # Filter out already completed models\n",
    "            models = {k: v for k, v in models.items() if k not in completed_models}\n",
    "            print(f\"Remaining models to train: {list(models.keys())}\")\n",
    "        else:\n",
    "            results = {}\n",
    "    else:\n",
    "        results = {}\n",
    "    \n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1_weighted': 'f1_weighted',\n",
    "        'f1_macro': 'f1_macro',\n",
    "        'precision_weighted': 'precision_weighted',\n",
    "        'recall_weighted': 'recall_weighted'\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for name, model in tqdm(models.items(), desc=\"Training models\"):\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Cross-validation\n",
    "            cv_results = cross_validate(\n",
    "                model, X_train, y_train,\n",
    "                cv=skf,\n",
    "                scoring=scoring,\n",
    "                return_train_score=True,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Train on full training set\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Test metrics\n",
    "            test_metrics = {\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'f1_weighted': f1_score(y_test, y_pred, average='weighted'),\n",
    "                'f1_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "                'precision_weighted': precision_score(y_test, y_pred, average='weighted'),\n",
    "                'recall_weighted': recall_score(y_test, y_pred, average='weighted'),\n",
    "                'matthews_corr': matthews_corrcoef(y_test, y_pred),\n",
    "                'cohen_kappa': cohen_kappa_score(y_test, y_pred)\n",
    "            }\n",
    "            \n",
    "            # Per-class metrics\n",
    "            class_report = classification_report(\n",
    "                y_test, y_pred,\n",
    "                target_names=label_encoder.classes_,\n",
    "                output_dict=True\n",
    "            )\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'cv_results': cv_results,\n",
    "                'test_metrics': test_metrics,\n",
    "                'class_report': class_report,\n",
    "                'predictions': y_pred,\n",
    "                'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "            }\n",
    "            \n",
    "            # Save checkpoint after each model\n",
    "            joblib.dump(results, checkpoint_file)\n",
    "            print(f\"üíæ Checkpoint saved ({len(results)}/{len(models) + len(results)} models completed)\")\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"  CV F1 (weighted): {cv_results['test_f1_weighted'].mean():.4f} (+/- {cv_results['test_f1_weighted'].std():.4f})\")\n",
    "            print(f\"  Test F1 (weighted): {test_metrics['f1_weighted']:.4f}\")\n",
    "            print(f\"  Test F1 (macro): {test_metrics['f1_macro']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error training {name}: {str(e)}\")\n",
    "            print(f\"   Skipping this model and continuing...\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train models on different sampling strategies\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING ON ORIGINAL DATA\")\n",
    "print(\"=\"*80)\n",
    "results_original = evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING ON SMOTE RESAMPLED DATA\")\n",
    "print(\"=\"*80)\n",
    "results_smote = evaluate_models(models, X_train_smote, y_train_smote, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOP PERFORMING MODELS\n",
      "================================================================================\n",
      "Strategy               Model  Test_F1_Macro  Test_F1_Weighted  F1_depression  F1_anxiety  F1_suicidal_ideation\n",
      "Original          Linear SVM       0.468318          0.872268       0.369363    0.351351              0.223022\n",
      "   SMOTE                 MLP       0.421385          0.873917       0.267183    0.329412              0.148515\n",
      "   SMOTE Logistic Regression       0.413008          0.814713       0.347868    0.274830              0.159555\n",
      "Original Logistic Regression       0.405433          0.796516       0.342682    0.262217              0.166667\n",
      "   SMOTE          Linear SVM       0.403648          0.814002       0.328516    0.255380              0.159836\n",
      "Original                 MLP       0.384131          0.883305       0.308872    0.225108              0.051282\n",
      "   SMOTE    Ridge Classifier       0.372500          0.778907       0.311968    0.209424              0.134111\n",
      "Original    Ridge Classifier       0.372202          0.769644       0.317295    0.210843              0.136913\n",
      "Original       Random Forest       0.370459          0.792990       0.231884    0.261168              0.133816\n",
      "   SMOTE       Random Forest       0.360390          0.808607       0.192954    0.222635              0.150134\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive comparison\n",
    "def create_results_comparison(results_dict):\n",
    "    \"\"\"Create comparison dataframe from results\"\"\"\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for strategy_name, results in results_dict.items():\n",
    "        for model_name, model_results in results.items():\n",
    "            row = {\n",
    "                'Strategy': strategy_name,\n",
    "                'Model': model_name,\n",
    "                'CV_F1_Weighted': model_results['cv_results']['test_f1_weighted'].mean(),\n",
    "                'CV_F1_Std': model_results['cv_results']['test_f1_weighted'].std(),\n",
    "                'Test_Accuracy': model_results['test_metrics']['accuracy'],\n",
    "                'Test_F1_Weighted': model_results['test_metrics']['f1_weighted'],\n",
    "                'Test_F1_Macro': model_results['test_metrics']['f1_macro'],\n",
    "                'Matthews_Corr': model_results['test_metrics']['matthews_corr'],\n",
    "                'Cohen_Kappa': model_results['test_metrics']['cohen_kappa']\n",
    "            }\n",
    "            \n",
    "            # Add per-class F1 scores\n",
    "            for cls in label_encoder.classes_:\n",
    "                row[f'F1_{cls}'] = model_results['class_report'][cls]['f1-score']\n",
    "            \n",
    "            comparison_data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "# Create comparison\n",
    "all_results = {\n",
    "    'Original': results_original,\n",
    "    'SMOTE': results_smote\n",
    "}\n",
    "\n",
    "comparison_df = create_results_comparison(all_results)\n",
    "\n",
    "# Display best models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP PERFORMING MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by macro F1 (better for imbalanced data)\n",
    "top_models = comparison_df.nlargest(10, 'Test_F1_Macro')\n",
    "\n",
    "display_cols = ['Strategy', 'Model', 'Test_F1_Macro', 'Test_F1_Weighted', \n",
    "                'F1_depression', 'F1_anxiety', 'F1_suicidal_ideation']\n",
    "\n",
    "print(top_models[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deep Learning Models - Transformer-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AraBERT model...\n",
      "Loading aubmindlab/bert-base-arabertv2...\n",
      "Found checkpoint at models/training_progress/arabert_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbedca406fe14a79bff21160750fa736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5a66e88ccd4fde8c4dcc5aa06e77fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6048, Train Acc: 0.7582\n",
      "Val Loss: 0.6721, Val F1 (weighted): 0.8037, Val F1 (macro): 0.4713\n",
      "üíæ Checkpoint saved to models/training_progress/arabert_checkpoint.pt\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b475bb8668244970966a24479aeb1030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac5295816934d8fa1059b9d5f0e2e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1733, Train Acc: 0.9408\n",
      "Val Loss: 0.6330, Val F1 (weighted): 0.8383, Val F1 (macro): 0.5080\n",
      "üíæ Checkpoint saved to models/training_progress/arabert_checkpoint.pt\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fca282d7990408493ef311142fb22af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a042362fc7a4a5bbba33eeacd6edbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1058, Train Acc: 0.9663\n",
      "Val Loss: 0.4910, Val F1 (weighted): 0.8837, Val F1 (macro): 0.5608\n",
      "üíæ Checkpoint saved to models/training_progress/arabert_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "# Create dataset class for transformers\n",
    "class ArabicMentalHealthDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Fine-tune AraBERT with checkpoint saving\n",
    "def train_arabert(X_train_text, y_train, X_test_text, y_test, \n",
    "                  model_name='aubmindlab/bert-base-arabertv2',\n",
    "                  epochs=5, batch_size=32, checkpoint_dir='models/training_progress'):\n",
    "    \n",
    "    print(f\"Loading {model_name}...\")\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'arabert_checkpoint.pt')\n",
    "    \n",
    "    # Check for existing checkpoint\n",
    "    start_epoch = 0\n",
    "    training_stats = []\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Found checkpoint at {checkpoint_path}\")\n",
    "        response = input(\"Resume from checkpoint? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            training_stats = checkpoint['training_stats']\n",
    "            print(f\"Resuming from epoch {start_epoch}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    if start_epoch > 0 and os.path.exists(checkpoint_path):\n",
    "        # Load from checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=len(label_encoder.classes_),\n",
    "            problem_type=\"single_label_classification\"\n",
    "        )\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(\"‚úÖ Loaded model weights from checkpoint\")\n",
    "    else:\n",
    "        # Load fresh model\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=len(label_encoder.classes_),\n",
    "            problem_type=\"single_label_classification\"\n",
    "        )\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ArabicMentalHealthDataset(X_train_text, y_train, tokenizer)\n",
    "    test_dataset = ArabicMentalHealthDataset(X_test_text, y_test, tokenizer)\n",
    "    \n",
    "    # Create weighted sampler for imbalanced data\n",
    "    class_counts = np.bincount(y_train)\n",
    "    weights = 1.0 / class_counts\n",
    "    sample_weights = weights[y_train]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    \n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(0.1 * total_steps),\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Load optimizer and scheduler state if resuming\n",
    "    if start_epoch > 0 and os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        print(\"‚úÖ Loaded optimizer and scheduler states\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels).item()\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'acc': correct_predictions / total_predictions\n",
    "            })\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Validation\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                val_loss += outputs.loss.item()\n",
    "                \n",
    "                _, preds = torch.max(outputs.logits, dim=1)\n",
    "                val_predictions.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "        val_f1_weighted = f1_score(val_labels, val_predictions, average='weighted')\n",
    "        val_f1_macro = f1_score(val_labels, val_predictions, average='macro')\n",
    "        \n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}, Val F1 (weighted): {val_f1_weighted:.4f}, Val F1 (macro): {val_f1_macro:.4f}\")\n",
    "        \n",
    "        training_stats.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_acc': train_accuracy,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_f1_weighted': val_f1_weighted,\n",
    "            'val_f1_macro': val_f1_macro\n",
    "        })\n",
    "        \n",
    "        # Save checkpoint after each epoch\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'training_stats': training_stats,\n",
    "            'val_f1_macro': val_f1_macro\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"üíæ Checkpoint saved to {checkpoint_path}\")\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    return model, training_stats, val_predictions\n",
    "\n",
    "# Train AraBERT\n",
    "print(\"Training AraBERT model...\")\n",
    "arabert_model, arabert_stats, arabert_predictions = train_arabert(\n",
    "    X_train_text, y_train, X_test_text, y_test,\n",
    "    epochs=3  # Reduce for demonstration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Interpretation and Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Linear SVM with Original strategy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ERROR ANALYSIS\n",
      "================================================================================\n",
      "Total misclassifications: 1289 (13.53%)\n",
      "\n",
      "anxiety:\n",
      "  Misclassified: 110 / 188 (58.51%)\n",
      "  Most confused with: neutral (84 times)\n",
      "\n",
      "depression:\n",
      "  Misclassified: 383 / 641 (59.75%)\n",
      "  Most confused with: neutral (332 times)\n",
      "\n",
      "neutral:\n",
      "  Misclassified: 717 / 8586 (8.35%)\n",
      "  Most confused with: depression (461 times)\n",
      "\n",
      "suicidal_ideation:\n",
      "  Misclassified: 79 / 110 (71.82%)\n",
      "  Most confused with: neutral (60 times)\n"
     ]
    }
   ],
   "source": [
    "# Select best model for interpretation\n",
    "best_model_name = comparison_df.nlargest(1, 'Test_F1_Macro')['Model'].values[0]\n",
    "best_strategy = comparison_df.nlargest(1, 'Test_F1_Macro')['Strategy'].values[0]\n",
    "best_model = all_results[best_strategy][best_model_name]['model']\n",
    "best_predictions = all_results[best_strategy][best_model_name]['predictions']\n",
    "\n",
    "print(f\"Best model: {best_model_name} with {best_strategy} strategy\")\n",
    "\n",
    "# Feature importance for tree-based models\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get feature names\n",
    "    tfidf_names = feature_engineer.tfidf_vectorizer.get_feature_names_out()\n",
    "    feature_names = list(tfidf_names) + available_numerical + [f'topic_{i}' for i in range(20)]\n",
    "    \n",
    "    # Get importances\n",
    "    importances = best_model.feature_importances_\n",
    "    \n",
    "    # Sort and select top features\n",
    "    indices = np.argsort(importances)[::-1][:30]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(f'Top 30 Feature Importances - {best_model_name}')\n",
    "    plt.bar(range(30), importances[indices])\n",
    "    plt.xticks(range(30), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Confusion matrix analysis\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Error analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Misclassified samples\n",
    "misclassified_mask = y_test != best_predictions\n",
    "misclassified_indices = np.where(misclassified_mask)[0]\n",
    "\n",
    "print(f\"Total misclassifications: {len(misclassified_indices)} ({len(misclassified_indices)/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "# Analyze misclassifications by class\n",
    "for true_class in range(len(label_encoder.classes_)):\n",
    "    class_mask = y_test == true_class\n",
    "    class_misclassified = misclassified_mask & class_mask\n",
    "    \n",
    "    if class_misclassified.sum() > 0:\n",
    "        print(f\"\\n{label_encoder.classes_[true_class]}:\")\n",
    "        print(f\"  Misclassified: {class_misclassified.sum()} / {class_mask.sum()} ({class_misclassified.sum()/class_mask.sum()*100:.2f}%)\")\n",
    "        \n",
    "        # Most common misclassification\n",
    "        pred_for_class = best_predictions[class_mask]\n",
    "        true_for_class = y_test[class_mask]\n",
    "        wrong_preds = pred_for_class[pred_for_class != true_for_class]\n",
    "        \n",
    "        if len(wrong_preds) > 0:\n",
    "            most_common_error = Counter(wrong_preds).most_common(1)[0]\n",
    "            print(f\"  Most confused with: {label_encoder.classes_[most_common_error[0]]} ({most_common_error[1]} times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clinical Validity Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLINICAL VALIDITY METRICS\n",
      "================================================================================\n",
      "\n",
      "Binary Classification (Any Mental Health Issue vs Neutral):\n",
      "  Sensitivity (Recall): 0.493\n",
      "  Specificity: 0.916\n",
      "  Positive Predictive Value: 0.392\n",
      "  Negative Predictive Value: 0.943\n",
      "  Number Needed to Screen: 20.6\n",
      "\n",
      "Per-Condition Sensitivity:\n",
      "  depression: 0.402\n",
      "  anxiety: 0.415\n",
      "  suicidal_ideation: 0.282\n",
      "\n",
      "================================================================================\n",
      "RISK STRATIFICATION\n",
      "================================================================================\n",
      "\n",
      "Predicted Risk Distribution:\n",
      "  CRITICAL  :   168 (  1.76%)\n",
      "  HIGH      :   756 (  7.94%)\n",
      "  MODERATE  :   256 (  2.69%)\n",
      "  LOW       :  8345 ( 87.61%)\n"
     ]
    }
   ],
   "source": [
    "# Clinical metrics for mental health detection\n",
    "def calculate_clinical_metrics(y_true, y_pred, positive_classes=['depression', 'anxiety', 'suicidal_ideation']):\n",
    "    \"\"\"Calculate clinically relevant metrics\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Convert to binary: any mental health issue vs neutral\n",
    "    positive_indices = [label_encoder.transform([cls])[0] for cls in positive_classes]\n",
    "    y_true_binary = np.isin(y_true, positive_indices).astype(int)\n",
    "    y_pred_binary = np.isin(y_pred, positive_indices).astype(int)\n",
    "    \n",
    "    # Sensitivity (recall for positive class)\n",
    "    results['sensitivity'] = recall_score(y_true_binary, y_pred_binary)\n",
    "    \n",
    "    # Specificity\n",
    "    tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "    fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "    results['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # Positive Predictive Value (Precision)\n",
    "    results['ppv'] = precision_score(y_true_binary, y_pred_binary)\n",
    "    \n",
    "    # Negative Predictive Value\n",
    "    tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "    fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "    results['npv'] = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    \n",
    "    # Number Needed to Screen\n",
    "    tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "    results['nns'] = len(y_pred) / tp if tp > 0 else float('inf')\n",
    "    \n",
    "    # Per-class sensitivity for critical conditions\n",
    "    for cls in positive_classes:\n",
    "        cls_idx = label_encoder.transform([cls])[0]\n",
    "        cls_mask = y_true == cls_idx\n",
    "        if cls_mask.sum() > 0:\n",
    "            cls_recall = recall_score(\n",
    "                y_true[cls_mask] == cls_idx,\n",
    "                y_pred[cls_mask] == cls_idx\n",
    "            )\n",
    "            results[f'{cls}_sensitivity'] = cls_recall\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate clinical metrics\n",
    "clinical_metrics = calculate_clinical_metrics(y_test, best_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL VALIDITY METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nBinary Classification (Any Mental Health Issue vs Neutral):\")\n",
    "print(f\"  Sensitivity (Recall): {clinical_metrics['sensitivity']:.3f}\")\n",
    "print(f\"  Specificity: {clinical_metrics['specificity']:.3f}\")\n",
    "print(f\"  Positive Predictive Value: {clinical_metrics['ppv']:.3f}\")\n",
    "print(f\"  Negative Predictive Value: {clinical_metrics['npv']:.3f}\")\n",
    "print(f\"  Number Needed to Screen: {clinical_metrics['nns']:.1f}\")\n",
    "\n",
    "print(\"\\nPer-Condition Sensitivity:\")\n",
    "for condition in ['depression', 'anxiety', 'suicidal_ideation']:\n",
    "    if f'{condition}_sensitivity' in clinical_metrics:\n",
    "        print(f\"  {condition}: {clinical_metrics[f'{condition}_sensitivity']:.3f}\")\n",
    "\n",
    "# Risk stratification\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RISK STRATIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define risk levels\n",
    "risk_mapping = {\n",
    "    'suicidal_ideation': 'CRITICAL',\n",
    "    'depression': 'HIGH',\n",
    "    'anxiety': 'MODERATE',\n",
    "    'neutral': 'LOW'\n",
    "}\n",
    "\n",
    "# Get predicted risk levels\n",
    "predicted_classes = label_encoder.inverse_transform(best_predictions)\n",
    "predicted_risks = [risk_mapping[cls] for cls in predicted_classes]\n",
    "\n",
    "# Count risk distributions\n",
    "risk_counts = Counter(predicted_risks)\n",
    "print(\"\\nPredicted Risk Distribution:\")\n",
    "for risk in ['CRITICAL', 'HIGH', 'MODERATE', 'LOW']:\n",
    "    count = risk_counts.get(risk, 0)\n",
    "    percentage = count / len(predicted_risks) * 100\n",
    "    print(f\"  {risk:10s}: {count:5d} ({percentage:6.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ethical Considerations and Limitations\n",
    "\n",
    "### Ethical Guidelines:\n",
    "1. **Privacy**: Ensure all data is anonymized and encrypted\n",
    "2. **Consent**: Obtain explicit consent for mental health screening\n",
    "3. **Clinical Integration**: Model should supplement, not replace, professional assessment\n",
    "4. **Crisis Management**: Implement immediate referral pathways for high-risk cases\n",
    "5. **Bias Monitoring**: Regular audits for demographic and linguistic biases\n",
    "\n",
    "### Limitations:\n",
    "1. **Data Quality**: Model performance depends on labeled data quality\n",
    "2. **Cultural Context**: May not generalize across all Arabic dialects/cultures\n",
    "3. **Temporal Validity**: Mental health expressions evolve; model needs updates\n",
    "4. **False Negatives**: Critical for suicidal ideation - requires conservative thresholds\n",
    "5. **Interpretability**: Deep learning models lack full explainability\n",
    "\n",
    "### Recommendations:\n",
    "1. Implement continuous monitoring and model updates\n",
    "2. Establish feedback loops with mental health professionals\n",
    "3. Develop region-specific model variants\n",
    "4. Create comprehensive documentation for clinical users\n",
    "5. Implement A/B testing framework for model improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MENTAL HEALTH DETECTION SYSTEM - FINAL REPORT\n",
      "================================================================================\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "  Total samples: 47,625\n",
      "  Class imbalance ratio: 78.2:1\n",
      "\n",
      "üèÜ Best Model Performance:\n",
      "  Model: Linear SVM (Original)\n",
      "  F1 Score (Macro): 0.4683\n",
      "  F1 Score (Weighted): 0.8723\n",
      "\n",
      "üè• Clinical Metrics:\n",
      "  Sensitivity: 0.493\n",
      "  Specificity: 0.916\n",
      "  Suicidal Ideation Detection: 0.282\n",
      "\n",
      "üìÅ Saved Artifacts:\n",
      "  - Model and pipeline: models/mental_health_model.pkl\n",
      "  - Results comparison: models/model_comparison_results.csv\n",
      "\n",
      "================================================================================\n",
      "Research notebook completed successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MENTAL HEALTH DETECTION SYSTEM - FINAL REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(df):,}\")\n",
    "print(f\"  Class imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Model Performance:\")\n",
    "print(f\"  Model: {best_model_name} ({best_strategy})\")\n",
    "print(f\"  F1 Score (Macro): {comparison_df.nlargest(1, 'Test_F1_Macro')['Test_F1_Macro'].values[0]:.4f}\")\n",
    "print(f\"  F1 Score (Weighted): {comparison_df.nlargest(1, 'Test_F1_Macro')['Test_F1_Weighted'].values[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nüè• Clinical Metrics:\")\n",
    "print(f\"  Sensitivity: {clinical_metrics['sensitivity']:.3f}\")\n",
    "print(f\"  Specificity: {clinical_metrics['specificity']:.3f}\")\n",
    "print(f\"  Suicidal Ideation Detection: {clinical_metrics.get('suicidal_ideation_sensitivity', 0):.3f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Saved Artifacts:\")\n",
    "print(f\"  - Model and pipeline: models/mental_health_model.pkl\")\n",
    "print(f\"  - Results comparison: models/model_comparison_results.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Research notebook completed successfully!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
